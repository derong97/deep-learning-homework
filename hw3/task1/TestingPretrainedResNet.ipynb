{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eq1_cxPSa5Wl"
   },
   "source": [
    "## Testing Pretrained ResNet101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KmvnOi18E0kT"
   },
   "source": [
    "### Test a sample using the pre-trained ResNet101 (original code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to /home/jovyan/.cache/torch/checkpoints/resnet101-5d3b4d8f.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb07bb8e1934143923c911c4ab174f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=178728960.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([3, 224, 224])\n",
      "Label: tensor(162) . Confidence Score: 81.00029754638672 %\n",
      "Label: tensor(168) . Confidence Score: 9.432700157165527 %\n",
      "Label: tensor(208) . Confidence Score: 2.8158085346221924 %\n",
      "Label: tensor(161) . Confidence Score: 1.579605221748352 %\n",
      "Label: tensor(211) . Confidence Score: 1.131980538368225 %\n"
     ]
    }
   ],
   "source": [
    "# https://learnopencv.com/pytorch-for-beginners-image-classification-using-pre-trained-models/\n",
    "\n",
    "import torch, torchvision\n",
    "from PIL import Image\n",
    "\n",
    "# load model\n",
    "resnet = torchvision.models.resnet101(pretrained=True)\n",
    "\n",
    "# set network to evaluation mode\n",
    "resnet.eval()\n",
    "\n",
    "transform = torchvision.transforms.Compose([          \n",
    " torchvision.transforms.Resize(256),                   \n",
    " torchvision.transforms.CenterCrop(224),               \n",
    " torchvision.transforms.ToTensor(),                     \n",
    " torchvision.transforms.Normalize(                      \n",
    " mean=[0.485, 0.456, 0.406],                            \n",
    " std=[0.229, 0.224, 0.225]                             \n",
    " )])\n",
    "\n",
    "\n",
    "img = Image.open(\"dog.jpg\") # You can download an image of a dog from Internet or capture an image by yourself.\n",
    "img_t = transform(img)\n",
    "print(img_t.shape)\n",
    "\n",
    "batch_t = torch.unsqueeze(img_t, 0)\n",
    "\n",
    "\n",
    "# perform inference\n",
    "out = resnet(batch_t)\n",
    "\n",
    "# print top-5 classes predicted by model\n",
    "_, indices = torch.sort(out, descending=True)\n",
    "percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
    "\n",
    "for idx in indices[0][:5]:\n",
    "    print('Label:', idx, '. Confidence Score:', percentage[idx].item(), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pge3-ER1M-Ss"
   },
   "source": [
    "Refer to https://gist.github.com/ageitgey/4e1342c10a71981d0b491e1b8227328b, to check if the predicted classes are meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-kkOJ6hNbOB"
   },
   "source": [
    "### Task (edited code)\n",
    "\n",
    "Modify the code above, to peform data augmentation for the testing sample (averaging the scores of 5 crops: center crop, upper left crop, lower left crop, lower right crop, upper right crop).\n",
    "\n",
    "Pls briefly discuss the advantages and disadvantages of using testing data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fZWY6lElTWRI",
    "outputId": "203a8fd9-aab7-467c-b3eb-69bdb330fc76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor(162) . Confidence Score: 99.99964141845703 %\n",
      "Label: tensor(168) . Confidence Score: 0.00034762214636430144 %\n",
      "Label: tensor(161) . Confidence Score: 1.0993042451445945e-05 %\n",
      "Label: tensor(164) . Confidence Score: 2.276629516018147e-07 %\n",
      "Label: tensor(166) . Confidence Score: 1.4632828282401533e-09 %\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "from PIL import Image\n",
    "\n",
    "# load model\n",
    "resnet = torchvision.models.resnet101(pretrained=True)\n",
    "\n",
    "# set network to evaluation mode\n",
    "resnet.eval()\n",
    "\n",
    "transform = torchvision.transforms.Compose([          \n",
    " torchvision.transforms.Resize(256),                   \n",
    " # torchvision.transforms.CenterCrop(224),               \n",
    " torchvision.transforms.ToTensor(),                     \n",
    " torchvision.transforms.Normalize(                      \n",
    " mean=[0.485, 0.456, 0.406],                            \n",
    " std=[0.229, 0.224, 0.225]                             \n",
    " )])\n",
    "\n",
    "img = Image.open(\"dog.jpg\")\n",
    "img_t = transform(img)\n",
    "\n",
    "height = img_t.shape[1]\n",
    "width = img_t.shape[2]\n",
    "\n",
    "# 5 slices of img_t\n",
    "center_crop = img_t[:, round(height/2 - 112): round(height/2 + 112), round(width/2 - 112): round(width/2 + 112)]\n",
    "upper_left_crop = img_t[:, :224, :224]\n",
    "lower_left_crop = img_t[:, height - 224:, :224]\n",
    "lower_right_crop = img_t[:, height - 224:, width - 224:]\n",
    "upper_right_crop = img_t[:, :224, width - 224:]\n",
    "\n",
    "batch_t = torch.stack((center_crop, upper_left_crop, lower_left_crop, lower_right_crop, upper_right_crop), 0)\n",
    "\n",
    "# perform inference\n",
    "out = resnet(batch_t)\n",
    "out_sum = torch.sum(out, 0) # sum the scores for each index across the entire batch\n",
    "\n",
    "# print top-5 classes predicted by model\n",
    "_, indices = torch.sort(out_sum, descending=True)\n",
    "percentage = torch.nn.functional.softmax(out_sum, dim=0) * 100\n",
    "\n",
    "for idx in indices[:5]:\n",
    "    print('Label:', idx, '. Confidence Score:', percentage[idx].item(), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LiND15XmkBpU"
   },
   "source": [
    "The code has been modified that takes into account the scores of 5 crops. I did not average the scores as I applied softmax after summing the scores for each index for all 5 crops in the minibatch.\n",
    "\n",
    "Advantages:\n",
    "- The prediction relies on multiple different views of the same image, instead of only 1 raw image, so the final score is more reliable.\n",
    "\n",
    "Disadvantages:\n",
    "- Longer prediction time as each augmented image needs to be generated and processed.\n",
    "- The cropped images might not always contain the object of interest, leading to incorrect predictions."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TestingPretrainedResNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
